{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ECCV18_initializers import *\n",
    "import Networks as STNet\n",
    "import SearchTools as search\n",
    "from ReportGenerator import R_Recall_at_T, mAP_at_k\n",
    "from scipy.spatial.distance import cdist\n",
    "import scipy.sparse as sps\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ################## Starting to learn network parameters:  ##################\n",
      "layer-units:\n",
      "** 1 **** 2 **** 3 **** 4 **** 5 **** 6 **** 7 **** 8 **** 9 **\n",
      "Finished learning network parameters:\n",
      " ---------- distortion vs. number of bits for training set:\n",
      "[ 1.          0.19276921  0.07762106  0.03607568  0.02900506  0.02366239\n",
      "  0.01937174  0.01585071  0.01298979  0.01064467]\n",
      "[   0.           69.29709831  155.45016866  248.78085882  275.03846935\n",
      "  301.51224918  328.10274028  354.66898781  381.25542906  407.82330912]\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "# Train the model:\n",
    "model_pretrain = STNet.BaseLearner(k,L,m=m,Learner=Learner,nlinStrategy='KBest_STC')\n",
    "model_pretrain.run(F_train)\n",
    "print(' ---------- distortion vs. number of bits for training set:')\n",
    "print(model_pretrain.distortion)\n",
    "print(model_pretrain.rate*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running the network:\n",
      " ##################  Running the network:  ##################\n",
      "layer-units:\n",
      "** 1 **** 2 **** 3 **** 4 **** 5 **** 6 **** 7 **** 8 **** 9 **\n",
      "Finished running the network.\n",
      " ---------- distortion vs. number of bits for the main database:\n",
      "[ 1.          0.19261927  0.07763419  0.03608795  0.02904271  0.02370401\n",
      "  0.01940824  0.01588608  0.01302185  0.01067161]\n",
      "[   0.           69.20689281  155.35767536  248.75004114  275.03884578\n",
      "  301.53732217  328.14167101  354.72349462  381.32521628  407.9101207 ]\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "# Encoding the entire database based on the trained parameters:\n",
    "obj_F = STNet.fwdPass(model_pretrain.params,k,nlinStrategy='KBest_STC')\n",
    "_,F_hat,X = obj_F.run(F)\n",
    "for l in range(L):\n",
    "    X[l] = sps.csc_matrix((X[l]))\n",
    "print(' ---------- distortion vs. number of bits for the main database:')\n",
    "print(obj_F.distortion)\n",
    "print(obj_F.rate*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running the network:\n",
      " ##################  Running the network:  ##################\n",
      "layer-units:\n",
      "** 1 **** 2 **** 3 **** 4 **** 5 **** 6 **** 7 **** 8 **** 9 **\n",
      "Finished running the network.\n",
      "[ 1.          0.19354975  0.0780981   0.03631615  0.02921068  0.02380542\n",
      "  0.01947944  0.01595261  0.01305724  0.01069532]\n",
      "[   0.           69.23310043  155.5943655   248.87906763  275.10526432\n",
      "  301.52307293  328.05062597  354.56814881  381.07445966  407.59448813]\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Encoding the queries based on the trained parameters:\n",
    "obj_Q = STNet.fwdPass(model_pretrain.params,k,nlinStrategy='KBest_STC')\n",
    "_,_,Y = obj_Q.run(Q)\n",
    "for l in range(L):\n",
    "    Y[l] = sps.csc_matrix((Y[l]))\n",
    "\n",
    "print(obj_Q.distortion)\n",
    "print(obj_Q.rate*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitList = \n",
      " [   0.           69.20689281  155.35767536  248.75004114  275.03884578\n",
      "  301.53732217  328.14167101  354.72349462  381.32521628  407.9101207 ]\n"
     ]
    }
   ],
   "source": [
    "##############################3\n",
    "# ANN databases have 3 sets: train, main and query. Other databases\n",
    "# like MNIST have train and test only.\n",
    "if trainset_mainset_seperated:\n",
    "    Distortion = obj_F.distortion\n",
    "    if rate_calc_exct:\n",
    "        BitList = [0]\n",
    "        for l in range(L):\n",
    "            alphabet_probs = \\\n",
    "                STNet.combinatorial_binomial_poisson_distributions\\\n",
    "                    (1 - obj_F.prob_z[l], obj_F.nlinParam[l])\n",
    "            BitList.append(STNet.categorical_entropy(alphabet_probs) + obj_F.nlinParam[l])\n",
    "        BitList = np.cumsum(BitList)\n",
    "    else:\n",
    "        BitList = obj_F.rate * n\n",
    "else:\n",
    "    Distortion = obj_Q.distortion\n",
    "    if rate_calc_exct:\n",
    "        BitList = [0]\n",
    "        for l in range(L):\n",
    "            alphabet_probs = \\\n",
    "                STNet.combinatorial_binomial_poisson_distributions\\\n",
    "                    (1 - obj_Q.prob_z[l], obj_Q.nlinParam[l])\n",
    "            BitList.append(STNet.categorical_entropy(alphabet_probs) + obj_Q.nlinParam[l])\n",
    "        BitList = np.cumsum(BitList)\n",
    "    else:\n",
    "        BitList = obj_Q.rate * n\n",
    "print('BitList = \\n',BitList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***************** Decoding layer l = 1  ****************\n",
      "elapsed time for initial decoding =  224.68936491012573\n",
      "initial 1-Recall@1 =  0.12\n",
      "initial mAP@100 =  0.0917953685330356\n",
      "elapsed time for list refinement =  13.353838920593262\n",
      "refined 1-Recall@1 =  0.21\n",
      "refined mAP@100 =  0.20462926246659863\n",
      " ***************** Decoding layer l = 2  ****************\n",
      "elapsed time for initial decoding =  318.0556619167328\n",
      "initial 1-Recall@1 =  0.17\n",
      "initial mAP@100 =  0.12694416878735115\n",
      "elapsed time for list refinement =  14.037405014038086\n",
      "refined 1-Recall@1 =  0.467\n",
      "refined mAP@100 =  0.5037658990043645\n",
      " ***************** Decoding layer l = 3  ****************\n",
      "elapsed time for initial decoding =  260.25286746025085\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.13198275759667039\n",
      "elapsed time for list refinement =  14.593857288360596\n",
      "refined 1-Recall@1 =  0.624\n",
      "refined mAP@100 =  0.6700595769573531\n",
      " ***************** Decoding layer l = 4  ****************\n",
      "elapsed time for initial decoding =  131.3538007736206\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  15.237019300460815\n",
      "refined 1-Recall@1 =  0.658\n",
      "refined mAP@100 =  0.7041796823613918\n",
      " ***************** Decoding layer l = 5  ****************\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  15.88500690460205\n",
      "refined 1-Recall@1 =  0.695\n",
      "refined mAP@100 =  0.7302111689492068\n",
      " ***************** Decoding layer l = 6  ****************\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  16.418002128601074\n",
      "refined 1-Recall@1 =  0.711\n",
      "refined mAP@100 =  0.7521406812988969\n",
      " ***************** Decoding layer l = 7  ****************\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  17.08193564414978\n",
      "refined 1-Recall@1 =  0.747\n",
      "refined mAP@100 =  0.7724195602617514\n",
      " ***************** Decoding layer l = 8  ****************\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  17.53427815437317\n",
      "refined 1-Recall@1 =  0.761\n",
      "refined mAP@100 =  0.7886811384180028\n",
      " ***************** Decoding layer l = 9  ****************\n",
      "initial 1-Recall@1 =  0.179\n",
      "initial mAP@100 =  0.1322454125852574\n",
      "elapsed time for list refinement =  18.0717990398407\n",
      "refined 1-Recall@1 =  0.778\n",
      "refined mAP@100 =  0.8033757499961456\n",
      " ***************** Finished the decoding ****************\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Initial decoding based on multi-layer codes:\n",
    "Recat1_initial = []\n",
    "Recat10_initial = []\n",
    "Recat100_initial = []\n",
    "mAP10_initial = []\n",
    "mAP100_initial = []\n",
    "Recat1_refined = []\n",
    "Recat10_refined = []\n",
    "Recat100_refined = []\n",
    "mAP10_refined = []\n",
    "mAP100_refined = []\n",
    "#\n",
    "Votes = np.zeros((N_f, N_q))\n",
    "# Heuristically weight the codes from different layers:\n",
    "# Vote_weight = obj_Q.distortion[0:-1] / obj_Q.distortion[1:]\n",
    "Vote_weight = obj_Q.distortion[1:] ** 2\n",
    "Vote_weight[vote_layer_dismiss:] = 0\n",
    "for l in range(L):\n",
    "    print(' ***************** Decoding layer l =',l+1, ' ****************')\n",
    "    ############################################################\n",
    "    # Initial decoding from STC:\n",
    "    if Vote_weight[l] != 0:\n",
    "        t = time.time()\n",
    "        tempVotes = Vote_weight[l] * search.ternaryVoter(X[l], Y[l], nu, nu_prime).toarray()\n",
    "        # tempVotes = STNet.nlinearity(tempVotes, 10000, 'KBest')\n",
    "        Votes += tempVotes\n",
    "        List_initial = np.argsort(-Votes, axis=0)[:initial_list_size, :]\n",
    "        print('elapsed time for initial decoding = ', time.time() - t)\n",
    "    #\n",
    "    Recat1_initial.append(R_Recall_at_T(Y_NNs, List_initial, R=1, T=1))\n",
    "    Recat10_initial.append(R_Recall_at_T(Y_NNs, List_initial, R=10, T=10))\n",
    "    Recat100_initial.append(R_Recall_at_T(Y_NNs, List_initial, R=100, T=100))\n",
    "    mAP10_initial.append(mAP_at_k(Y_NNs[0:10,:], List_initial[0:10,:], k=10))\n",
    "    mAP100_initial.append(mAP_at_k(Y_NNs[0:100,:], List_initial[0:100,:], k=100))\n",
    "    print('initial 1-Recall@1 = ', Recat1_initial[-1])\n",
    "    print('initial mAP@100 = ', mAP100_initial[-1])\n",
    "    ############################################################\n",
    "    t = time.time()\n",
    "    # Final decoding based on reconstructions:\n",
    "    List_refined = search.List_refiner(np.sum(F_hat[0:l+1], axis=0), Q, List_initial)\n",
    "    #\n",
    "    Recat1_refined.append(R_Recall_at_T(Y_NNs, List_refined, R=1, T=1))\n",
    "    Recat10_refined.append(R_Recall_at_T(Y_NNs, List_refined, R=10, T=10))\n",
    "    Recat100_refined.append(R_Recall_at_T(Y_NNs, List_refined, R=100, T=100))\n",
    "    mAP10_refined.append(mAP_at_k(Y_NNs[0:10,:], List_refined[0:10,:], k=10))\n",
    "    mAP100_refined.append(mAP_at_k(Y_NNs[0:100,:], List_refined[0:100,:], k=100))\n",
    "    print('elapsed time for list refinement = ', time.time() - t)\n",
    "    print('refined 1-Recall@1 = ', Recat1_refined[-1])\n",
    "    print('refined mAP@100 = ', mAP100_refined[-1])\n",
    "\n",
    "print(' ***************** Finished the decoding ****************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##################################################################\n",
    "# Saving the results:\n",
    "suffix = '_k' + str(int(np.mean(k))) + '_L' + str(L) + '_m' + str(int(np.mean(m))) + '_'+ Learner\n",
    "fname = '/' + Database + '_D_Bit'  + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList, Distortion]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_Recat1_initial_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat1_initial]), fmt='%8f')\n",
    "#s\n",
    "fname = '/' + Database + '_Recat10_initial_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat10_initial]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_Recat100_initial_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat100_initial]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_mAP10_initial_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], mAP10_initial]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_mAP100_initial_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], mAP100_initial]), fmt='%8f')\n",
    "#\n",
    "\n",
    "fname = '/' + Database + '_Recat1_refined_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat1_refined]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_Recat10_refined_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat10_refined]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_Recat100_refined_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], Recat100_refined]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_mAP10_refined_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], mAP10_refined]), fmt='%8f')\n",
    "#\n",
    "fname = '/' + Database + '_mAP100_refined_Bit' + suffix\n",
    "np.savetxt(PGF_path + fname + '.dat', np.transpose([BitList[1:], mAP100_refined]), fmt='%8f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you want to free RAM after the experiments are finished:\n",
    "import os\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
